{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963e72c2",
   "metadata": {},
   "source": [
    "# Overview:\n",
    "Model CI/CD pipeline designed to automatically trigger model re-training upon detection of data drift.  \n",
    "Methodology:  \n",
    "- Develop a baseline regression model using synthetic data, incorporating some random variables to simulate potential future drift  \n",
    "- Initiate re-training when a performance drop is observed (e.g., increased RMSE)  \n",
    "- Consider model versioning  \n",
    "- Consider data versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8b3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a753d7",
   "metadata": {},
   "source": [
    "## Baseline model with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function Definitions and Coefficient Setup ---\n",
    "\n",
    "def dynamic_true_function(features, coeffs, noise_level=0.0):\n",
    "    \"\"\"Calculates the target value based on dynamic coefficients.\"\"\"\n",
    "    # np.dot is a clean way to do: c1*v1 + c2*v2 + ... + intercept\n",
    "    base_value = np.dot(features, coeffs[:-1]) + coeffs[-1]\n",
    "    if noise_level > 0:\n",
    "        noise = np.random.normal(0, noise_level, size=base_value.shape)\n",
    "        return base_value + noise\n",
    "    return base_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6a2c8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5, -2. ,  1. ,  3. , -4. ,  2. ,  5. ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "708390e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Drifted coefficients for simulating a change in production\n",
    "drift_scale = 0.1 # The magnitude of the drift\n",
    "#np.random.seed(0) # Make the drift predictable for this example run\n",
    "drift = np.random.normal(0, drift_scale, size=base_coeffs.shape)\n",
    "drifted_coeffs = base_coeffs + drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2123d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Coefficient Setup ---\n",
      "Base Coefficients:    [ 1.5 -2.   1.   3.  -4.   2.   5. ]\n",
      "Drifted Coefficients: [ 1.68 -1.96  1.1   3.22 -3.81  1.9   5.1 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Original coefficients for training\n",
    "base_coeffs = np.array([1.5, -2.0, 1.0, 3.0, -4.0, 2.0, 5.0])\n",
    "\n",
    "# 2. Drifted coefficients for simulating a change in production\n",
    "drift_scale = 0.1 # The magnitude of the drift\n",
    "np.random.seed(0) # Make the drift predictable for this example run\n",
    "drift = np.random.normal(0, drift_scale, size=base_coeffs.shape)\n",
    "drifted_coeffs = base_coeffs + drift\n",
    "\n",
    "print(\"--- Coefficient Setup ---\")\n",
    "print(f\"Base Coefficients:    {np.round(base_coeffs, 2)}\")\n",
    "print(f\"Drifted Coefficients: {np.round(drifted_coeffs, 2)}\\n\")\n",
    "\n",
    "# --- Helper function for data generation ---\n",
    "def generate_data(n_samples, coeffs, noise_level):\n",
    "    \"\"\"Generates a feature matrix (X) and target vector (y)\"\"\"\n",
    "    x = np.random.uniform(-3, 3, size=n_samples)\n",
    "    y = np.random.uniform(-4, 4, size=n_samples)\n",
    "    a = np.random.normal(0, 2, size=n_samples)\n",
    "    b = np.random.normal(5, 1.5, size=n_samples)\n",
    "    c = np.random.uniform(0, 10, size=n_samples)\n",
    "    d = np.random.normal(-2, 1, size=n_samples)\n",
    "    e = np.random.uniform(-1, 1, size=n_samples)\n",
    "\n",
    "    features_df = pd.DataFrame({\n",
    "        'v1': x**4, 'v2': y**3, 'v3': a**2 * b,\n",
    "        'v4': c**2, 'v5': d, 'v6': e\n",
    "    })\n",
    "    \n",
    "    X = features_df.values\n",
    "    y_target = dynamic_true_function(X, coeffs, noise_level)\n",
    "    return X, y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f718de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PHASE 1: Initial Model Training ---\n",
      "Training model on original data...\n",
      "Initial model performance on non-drifted test data (R2): 0.9515\n",
      "\n",
      "Initial model and scaler saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 1: INITIAL MODEL TRAINING (using BASE coefficients)\n",
    "# =============================================================================\n",
    "print(\"--- PHASE 1: Initial Model Training ---\")\n",
    "n_train_samples = 500000\n",
    "output_noise_level = 25.0\n",
    "\n",
    "# Generate training data using the ORIGINAL function\n",
    "X_train_full, y_train_full = generate_data(n_train_samples, base_coeffs, output_noise_level)\n",
    "\n",
    "# Split and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training model on original data...\")\n",
    "model = MLPRegressor(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=500,\n",
    "                     early_stopping=True, n_iter_no_change=15, verbose=False, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on its own test set to confirm it learned well\n",
    "y_pred_initial = model.predict(X_test_scaled)\n",
    "r2_initial = r2_score(y_test, y_pred_initial)\n",
    "print(f\"Initial model performance on non-drifted test data (R2): {r2_initial:.4f}\\n\")\n",
    "\n",
    "# Save the artifacts\n",
    "joblib.dump(model, \"multivariate_model_v1.joblib\")\n",
    "joblib.dump(scaler, \"scaler_v1.joblib\")\n",
    "print(\"Initial model and scaler saved.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f618a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PHASE 2: Simulating Production with Concept Drift ---\n",
      "Generating new 'production' data using the DRIFTED function...\n",
      "\n",
      "--- Performance Evaluation on Drifted Data ---\n",
      "The original model's performance on the new, drifted data (R2): 0.9406\n",
      "The original model's performance on non-drifted data (R2):     0.9515\n",
      "\n",
      "CONCLUSION: The R2 score has dropped significantly. This performance degradation\n",
      "is exactly what your CI/CD monitoring system should detect to trigger a retrain!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 2: SIMULATING PRODUCTION WITH CONCEPT DRIFT\n",
    "# =============================================================================\n",
    "print(\"--- PHASE 2: Simulating Production with Concept Drift ---\")\n",
    "print(\"Generating new 'production' data using the DRIFTED function...\")\n",
    "n_prod_samples = 10000\n",
    "\n",
    "# Generate new data using the DRIFTED coefficients\n",
    "X_prod, y_prod_ground_truth = generate_data(n_prod_samples, drifted_coeffs, output_noise_level)\n",
    "\n",
    "# IMPORTANT: We must use the OLD scaler from training\n",
    "X_prod_scaled = scaler.transform(X_prod)\n",
    "\n",
    "# Use the OLD model to make predictions on the NEW, drifted data\n",
    "y_pred_drifted = model.predict(X_prod_scaled)\n",
    "\n",
    "# Evaluate how well the old model did on the new data\n",
    "r2_drifted = r2_score(y_prod_ground_truth, y_pred_drifted)\n",
    "mse_drifted = mean_squared_error(y_prod_ground_truth, y_pred_drifted)\n",
    "\n",
    "print(\"\\n--- Performance Evaluation on Drifted Data ---\")\n",
    "print(f\"The original model's performance on the new, drifted data (R2): {r2_drifted:.4f}\")\n",
    "print(f\"The original model's performance on non-drifted data (R2):     {r2_initial:.4f}\")\n",
    "print(\"\\nCONCLUSION: The R2 score has dropped significantly. This performance degradation\")\n",
    "print(\"is exactly what your CI/CD monitoring system should detect to trigger a retrain!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
