{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceefce74",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "Take it easy and start with a simple decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15641d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af57b7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy on Iris dataset: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Decision Tree accuracy on Iris dataset: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f51bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model/decision_tree_clf.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348cff7",
   "metadata": {},
   "source": [
    "## Try prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4caf6cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success! API call was successful.\n",
      "------------------------------\n",
      "   Input data: [5.1, 3.5, 1.4, 0.2]\n",
      "   Prediction received: [0]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# In a new Jupyter cell\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# --- 1. Define the API Endpoint and Data ---\n",
    "\n",
    "# The URL of the API endpoint running in your Docker container\n",
    "# Remember we mapped port 5001 on our host to port 5000 in the container\n",
    "api_url = \"http://localhost:5001/predict\"\n",
    "\n",
    "# The data you want to send for prediction.\n",
    "# The structure MUST match what your Flask app expects: a dictionary with a \"features\" key.\n",
    "# Let's say your model was trained on 4 features (e.g., Iris dataset).\n",
    "test_data = {\n",
    "    \"features\": [5.1, 3.5, 1.4, 0.2]  # Example: Sepal Length, Sepal Width, Petal Length, Petal Width\n",
    "}\n",
    "\n",
    "\n",
    "# --- 2. Send the POST Request ---\n",
    "\n",
    "# The requests.post() function sends an HTTP POST request.\n",
    "# The `json` parameter automatically does two things:\n",
    "#   1. It serializes your Python dictionary `test_data` into a JSON string.\n",
    "#   2. It sets the `Content-Type` header to `application/json`.\n",
    "try:\n",
    "    response = requests.post(api_url, json=test_data)\n",
    "    response.raise_for_status()  # This will raise an exception for bad status codes (4xx or 5xx)\n",
    "\n",
    "    # --- 3. Process the Response ---\n",
    "\n",
    "    # The server responds with JSON, so we can parse it using the .json() method\n",
    "    prediction_result = response.json()\n",
    "\n",
    "    print(f\"✅ Success! API call was successful.\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"   Input data: {test_data['features']}\")\n",
    "    print(f\"   Prediction received: {prediction_result['prediction']}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "except requests.exceptions.ConnectionError as e:\n",
    "    print(f\"❌ Error: Could not connect to the API.\")\n",
    "    print(f\"   Please ensure the Docker container is running and the URL '{api_url}' is correct.\")\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"❌ Error: An HTTP error occurred.\")\n",
    "    print(f\"   Status Code: {e.response.status_code}\")\n",
    "    print(f\"   Response Body: {e.response.text}\") # Show the error message from the server\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af5113a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': 'setosa',\n",
       " 'features': [5.1, 3.5, 1.4, 0.2],\n",
       " 'model_version': 'Decision Tree Classifier v1.0',\n",
       " 'prediction': [0]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
