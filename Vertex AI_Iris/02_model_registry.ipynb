{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c88e21-d41b-4cb8-bb56-f254fdcf8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34d773-a01f-4461-82ff-f3273f8a9a99",
   "metadata": {},
   "source": [
    "# Summary \n",
    "Necessary steps to upload model to Vertex AI for implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d080e1-2022-4df5-8c1d-81ffa7cc9a91",
   "metadata": {},
   "source": [
    "## Input \n",
    "Some basic input about location, storage,... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c059c75-ab2e-4b43-afab-2a505ba63dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARTIFACT_DIR = \"model\"  # @param {type:\"string\"}\n",
    "REPOSITORY = \"experiment-iris-repository\"  # @param {type:\"string\"}\n",
    "IMAGE = \"experiment_iris_image\"  # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = \"experiment_iris_model\"  # @param {type:\"string\"}\n",
    "USER_SRC_DIR = \"src\"  # @param {type:\"string\"}\n",
    "LOCAL_MODEL_ARTIFACTS_DIR = \"model\"  # @param {type:\"string\"}\n",
    "REGION='asia-southeast1'\n",
    "PROJECT_ID='teak-store-392915'\n",
    "BUCKET_URI='gs://gcp_asia/ml_pipeline_experiment_20240825'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9807423-1284-4331-8487-586111476872",
   "metadata": {},
   "source": [
    "Create requirements.txt which contains all necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6dee3b-58f5-4e8c-845e-e48fb6f34dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "fastapi\n",
    "uvicorn==0.17.6\n",
    "joblib~=1.0\n",
    "numpy~=1.20\n",
    "scikit-learn~=0.24\n",
    "google-cloud-storage>=1.26.0,<2.0.0dev\n",
    "google-cloud-aiplatform[prediction]>=1.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7901bc-c049-414b-8d85-fabcbbf7f438",
   "metadata": {},
   "source": [
    "Create and load preprocessing module. Its to preprocess the data before predict with model   \n",
    "Iris dataset is simple so I decide do nothing so keep it blank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c29fc0-fa9a-45a1-9973-acc232ff3fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $USER_SRC_DIR/preprocess.py\n",
    "import numpy as np\n",
    "\n",
    "class MySimpleScaler(object):\n",
    "    def __init__(self):\n",
    "        self._means = None\n",
    "        self._stds = None\n",
    "\n",
    "    def preprocess(self, data):\n",
    "#         if self._means is None:  # during training only\n",
    "#             self._means = np.mean(data, axis=0)\n",
    "\n",
    "#         if self._stds is None:  # during training only\n",
    "#             self._stds = np.std(data, axis=0)\n",
    "#             if not self._stds.all():\n",
    "#                 raise ValueError(\"At least one column has standard deviation of 0.\")\n",
    "\n",
    "        # return (data - self._means) / self._stds\n",
    "         return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ddd8cef-f734-4b80-8377-93a17ca81614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/ml_pipeline/experiment_iris/src\n"
     ]
    }
   ],
   "source": [
    "%cd $USER_SRC_DIR/\n",
    "\n",
    "import pickle\n",
    "\n",
    "import joblib\n",
    "from preprocess import MySimpleScaler\n",
    "\n",
    "scaler = MySimpleScaler()\n",
    "\n",
    "with open(f\"../{LOCAL_MODEL_ARTIFACTS_DIR}/preprocessor.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0666e8-2013-4fcf-8444-7aca889fc2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# !gsutil cp {LOCAL_MODEL_ARTIFACTS_DIR}/* {BUCKET_URI}/{MODEL_ARTIFACT_DIR}/\n",
    "# !gsutil ls {BUCKET_URI}/{MODEL_ARTIFACT_DIR}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c85486-c15c-4316-b147-1cc5efef0791",
   "metadata": {},
   "source": [
    "Create predictor class to control following steps:\n",
    "- Preprocessor\n",
    "- Predictor\n",
    "- Handler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e33d0532-d5ca-4af4-a6c1-a1da33918e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/ml_pipeline/experiment_iris\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/ml_pipeline/experiment_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68292ee1-627e-4b67-ab7b-9344fb87b26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor.py\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "class CprPredictor(Predictor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri: str):\n",
    "        \"\"\"Loads the preprocessor and model artifacts.\"\"\"\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "\n",
    "        with open(\"preprocessor.pkl\", \"rb\") as f:\n",
    "            preprocessor = pickle.load(f)\n",
    "\n",
    "        self._class_names = load_iris().target_names\n",
    "        self._model = joblib.load(\"decision_tree_model_iris_v1.joblib\")\n",
    "        self._preprocessor = preprocessor\n",
    "\n",
    "    def predict(self, instances):\n",
    "        \"\"\"Performs prediction.\"\"\"\n",
    "        inputs = np.asarray(instances)\n",
    "        preprocessed_inputs = self._preprocessor.preprocess(inputs)\n",
    "        outputs = self._model.predict(preprocessed_inputs)\n",
    "\n",
    "        return {\"predictions\": [self._class_names[class_num] for class_num in outputs]}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bafde-eb14-45c5-9d9b-d0da8e5a2f33",
   "metadata": {},
   "source": [
    "## Package model into a container object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8178586b-82da-4e9b-acbe-63947e0857f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import docker\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from src.predictor import  CprPredictor  # Update this path as the variable $USER_SRC_DIR to import the custom predictor.\n",
    "\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    USER_SRC_DIR,\n",
    "    \n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\",\n",
    "    base_image=\"python:3.7\",\n",
    "    predictor=CprPredictor,  # Update this to the custom predictor class.\n",
    "    requirements_path=os.path.join(USER_SRC_DIR, \"requirements.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3ff3a09c-c8a9-462f-bdbd-d44fc5fde284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"asia-southeast1-docker.pkg.dev/teak-store-392915/experiment-iris-repository/experiment_iris_image\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97c1dd-4ec5-4d28-b32e-3f90d004463c",
   "metadata": {
    "id": "212b2935ea12",
    "tags": []
   },
   "source": [
    "### Push the container to artifact registry\n",
    "\n",
    "Configure Docker to access Artifact Registry. Then push your container image to your Artifact Registry repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d27b2b-0aa5-4cb4-b199-ffe94a4ccac6",
   "metadata": {
    "id": "ABE9UpwSdluK"
   },
   "source": [
    "If `artifactregistry.googleapis.com` is not enabled in your project, enable the API before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "668690db-c970-47fa-960e-d0b4095bf457",
   "metadata": {
    "collapsed": true,
    "id": "wSFXCj3LdluJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                         TITLE\n",
      "aiplatform.googleapis.com                    Vertex AI API\n",
      "analyticshub.googleapis.com                  Analytics Hub API\n",
      "apigateway.googleapis.com                    API Gateway API\n",
      "appengine.googleapis.com                     App Engine Admin API\n",
      "artifactregistry.googleapis.com              Artifact Registry API\n",
      "automl.googleapis.com                        Cloud AutoML API\n",
      "autoscaling.googleapis.com                   Cloud Autoscaling API\n",
      "backupdr.googleapis.com                      Backup and DR Service API\n",
      "bigquery.googleapis.com                      BigQuery API\n",
      "bigqueryconnection.googleapis.com            BigQuery Connection API\n",
      "bigquerydatapolicy.googleapis.com            BigQuery Data Policy API\n",
      "bigquerydatatransfer.googleapis.com          BigQuery Data Transfer API\n",
      "bigquerymigration.googleapis.com             BigQuery Migration API\n",
      "bigqueryreservation.googleapis.com           BigQuery Reservation API\n",
      "bigquerystorage.googleapis.com               BigQuery Storage API\n",
      "cloudapis.googleapis.com                     Google Cloud APIs\n",
      "cloudbuild.googleapis.com                    Cloud Build API\n",
      "cloudfunctions.googleapis.com                Cloud Functions API\n",
      "cloudresourcemanager.googleapis.com          Cloud Resource Manager API\n",
      "cloudscheduler.googleapis.com                Cloud Scheduler API\n",
      "cloudtrace.googleapis.com                    Cloud Trace API\n",
      "composer.googleapis.com                      Cloud Composer API\n",
      "compute.googleapis.com                       Compute Engine API\n",
      "connectors.googleapis.com                    Connectors API\n",
      "container.googleapis.com                     Kubernetes Engine API\n",
      "containerfilesystem.googleapis.com           Container File System API\n",
      "containerregistry.googleapis.com             Container Registry API\n",
      "datacatalog.googleapis.com                   Google Cloud Data Catalog API\n",
      "dataflow.googleapis.com                      Dataflow API\n",
      "dataform.googleapis.com                      Dataform API\n",
      "datalineage.googleapis.com                   Data Lineage API\n",
      "datapipelines.googleapis.com                 Data pipelines API\n",
      "dataplex.googleapis.com                      Cloud Dataplex API\n",
      "dataproc-control.googleapis.com              Cloud Dataproc Control API\n",
      "dataproc.googleapis.com                      Cloud Dataproc API\n",
      "datastore.googleapis.com                     Cloud Datastore API\n",
      "datastream.googleapis.com                    Datastream API\n",
      "deploymentmanager.googleapis.com             Cloud Deployment Manager V2 API\n",
      "dns.googleapis.com                           Cloud DNS API\n",
      "eventarc.googleapis.com                      Eventarc API\n",
      "eventarcpublishing.googleapis.com            Eventarc Publishing API\n",
      "fcm.googleapis.com                           Firebase Cloud Messaging API\n",
      "file.googleapis.com                          Cloud Filestore API\n",
      "firebase.googleapis.com                      Firebase Management API\n",
      "firebasedynamiclinks.googleapis.com          Firebase Dynamic Links API\n",
      "firebasehosting.googleapis.com               Firebase Hosting API\n",
      "firebaseinstallations.googleapis.com         Firebase Installations API\n",
      "firebaseremoteconfig.googleapis.com          Firebase Remote Config API\n",
      "firebaseremoteconfigrealtime.googleapis.com  Firebase Remote Config Realtime API\n",
      "firebaserules.googleapis.com                 Firebase Rules API\n",
      "firestore.googleapis.com                     Cloud Firestore API\n",
      "gkebackup.googleapis.com                     Backup for GKE API\n",
      "iam.googleapis.com                           Identity and Access Management (IAM) API\n",
      "iamcredentials.googleapis.com                IAM Service Account Credentials API\n",
      "identitytoolkit.googleapis.com               Identity Toolkit API\n",
      "language.googleapis.com                      Cloud Natural Language API\n",
      "logging.googleapis.com                       Cloud Logging API\n",
      "monitoring.googleapis.com                    Cloud Monitoring API\n",
      "networkconnectivity.googleapis.com           Network Connectivity API\n",
      "notebooks.googleapis.com                     Notebooks API\n",
      "osconfig.googleapis.com                      OS Config API\n",
      "oslogin.googleapis.com                       Cloud OS Login API\n",
      "pubsub.googleapis.com                        Cloud Pub/Sub API\n",
      "run.googleapis.com                           Cloud Run Admin API\n",
      "runtimeconfig.googleapis.com                 Cloud Runtime Configuration API\n",
      "secretmanager.googleapis.com                 Secret Manager API\n",
      "securetoken.googleapis.com                   Token Service API\n",
      "servicecontrol.googleapis.com                Service Control API\n",
      "servicemanagement.googleapis.com             Service Management API\n",
      "servicenetworking.googleapis.com             Service Networking API\n",
      "serviceusage.googleapis.com                  Service Usage API\n",
      "source.googleapis.com                        Legacy Cloud Source Repositories API\n",
      "sql-component.googleapis.com                 Cloud SQL\n",
      "sqladmin.googleapis.com                      Cloud SQL Admin API\n",
      "storage-api.googleapis.com                   Google Cloud Storage JSON API\n",
      "storage-component.googleapis.com             Cloud Storage\n",
      "storage.googleapis.com                       Cloud Storage API\n",
      "testing.googleapis.com                       Cloud Testing API\n",
      "translate.googleapis.com                     Cloud Translation API\n",
      "vision.googleapis.com                        Cloud Vision API\n",
      "visionai.googleapis.com                      Vision AI API\n",
      "vmmigration.googleapis.com                   VM Migration API\n",
      "vpcaccess.googleapis.com                     Serverless VPC Access API\n"
     ]
    }
   ],
   "source": [
    "!gcloud services list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4b5e8-2cd1-4c5f-b18a-ad69bf9f1711",
   "metadata": {
    "id": "ABE9UpwSdluK"
   },
   "source": [
    "If `artifactregistry.googleapis.com` is not enabled in your project, enable the API before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e5fdc4-b7c0-4b53-aea3-b30c6c8c1f53",
   "metadata": {
    "id": "qDhLoQMydluK"
   },
   "outputs": [],
   "source": [
    "#!gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173683b3-a709-4c8a-96d1-ab6a6dfac84d",
   "metadata": {
    "id": "09ffe2434e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [experiment-iris-repository]\n",
      "Waiting for operation [projects/teak-store-392915/locations/asia-southeast1/ope\n",
      "rations/77ff87c9-19d0-4619-9999-2c6b0ae6b740] to complete...done.              \n",
      "Created repository [experiment-iris-repository].\n"
     ]
    }
   ],
   "source": [
    "!gcloud artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06785ee9-18d7-49a8-b0c7-1801a65fbbf5",
   "metadata": {
    "id": "293437024749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding credentials for: asia-southeast1-docker.pkg.dev\n",
      "Docker configuration file updated.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec77d3-f5d5-4242-9523-7f5ad65e5f2b",
   "metadata": {
    "id": "33abf1328c52"
   },
   "source": [
    "Use SDK to push the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ea61375f-1e2d-43fd-8c8d-ca937b6ca1d4",
   "metadata": {
    "id": "1dd7448f4703"
   },
   "outputs": [],
   "source": [
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17d4cb-929b-41af-b1d1-1603c09f3d1c",
   "metadata": {
    "id": "b438bfa2129f"
   },
   "source": [
    "## Deploy to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86878c07-c6ae-4e29-acc7-60c74a8147fc",
   "metadata": {
    "id": "8d682d8388ec"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49a230f-0c8a-454c-a58d-3c08f7f6e845",
   "metadata": {
    "id": "574fb82d3eed"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d9bfc-9413-47ec-ad85-5368a7677146",
   "metadata": {
    "id": "4d7aab416c43"
   },
   "source": [
    "Use the LocalModel instance to upload the model. It will populate the container spec automatically for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ee26855-2e15-47a5-9f74-843f089ea16a",
   "metadata": {
    "id": "2738154345d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/958509004100/locations/asia-southeast1/models/8350861181702897664/operations/6303553488353755136\n",
      "Model created. Resource name: projects/958509004100/locations/asia-southeast1/models/8350861181702897664@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/958509004100/locations/asia-southeast1/models/8350861181702897664@1')\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    local_model=local_model,\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=f\"{BUCKET_URI}/{MODEL_ARTIFACT_DIR}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv) (Local)",
   "language": "python",
   "name": "local-virtualenv_khang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
